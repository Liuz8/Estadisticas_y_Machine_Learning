{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6de80dbc",
   "metadata": {},
   "source": [
    "# Bloque 1 - Clasificando datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ce19f7",
   "metadata": {},
   "source": [
    "## Utilidad del metodo score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45743072",
   "metadata": {},
   "source": [
    "Durante la construcción de un modelo para clasificar transacciones bancarias como legítimas o fraudulentas, una persona científica de datos utilizó la biblioteca Scikit-Learn, que ofrece diversos algoritmos de machine learning que pueden ser utilizados para la clasificación de datos. En cada uno de estos algoritmos, el método ``fit()`` se utiliza para entrenar un modelo a partir de las variables explicativas y la variable respuesta.\n",
    "\n",
    "Sin embargo, después del entrenamiento del modelo, se realiza un paso más mediante el uso del método ``score()``. Seleccione la alternativa que describe de manera adecuada la finalidad de usar el ``score()`` en este contexto:\n",
    "\n",
    "**Se utiliza para evaluar el desempeño del modelo ajustado.**\n",
    "\n",
    "El método ``score()`` tiene la finalidad de comparar las predicciones realizadas por el modelo con los valores reales de los datos y calcula una tasa de acierto en porcentaje llamada exactitud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb09f397",
   "metadata": {},
   "source": [
    "## parametros test_size=0.15,stratify=y,random_state=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9836a88b",
   "metadata": {},
   "source": [
    "¡Hola! Luri aquí. ¡Claro que sí! Con gusto te explico la función de cada uno de esos parámetros en el contexto de la división de datos para entrenamiento y prueba:\n",
    "1. ``test_size=0.15:``\n",
    "Este parámetro define la proporción del conjunto de datos que se utilizará para la prueba (o test). En este caso, ``0.15`` significa que el 15% de los datos originales se reservarán para evaluar el rendimiento final del modelo. El 85% restante se utilizará para entrenamiento y validación.\n",
    "Analogía: Imagina que tienes un pastel y quieres probar si está bien hecho. ``test_size`` sería el tamaño de la porción que cortas para probar (15% del pastel en este caso).\n",
    "\n",
    "\n",
    "2. ``stratify=y:``\n",
    "Este parámetro es crucial cuando tienes un problema de clasificación con clases desbalanceadas (es decir, cuando una clase tiene muchas más muestras que otra). Al usar ``stratify=y``, le indicas a la función que mantenga la proporción de las clases en los conjuntos de entrenamiento y prueba.\n",
    "\n",
    "**¿Por qué es importante?** Si no estratificas, podrías terminar con un conjunto de prueba que no represente bien la distribución original de las clases, lo que llevaría a una evaluación sesgada del modelo.\n",
    "\n",
    "**Analogía**: Imagina que tienes una bolsa con 90 canicas rojas y 10 azules (desbalanceo). Si divides la bolsa al azar, podrías obtener una porción con muchas más canicas rojas que azules, lo cual no sería representativo. ``stratify`` asegura que cada porción tenga aproximadamente la misma proporción de rojas y azules que la bolsa original.\n",
    "\n",
    "**En el contexto de la clase**: En el contexto de la clase, se busca mantener la proporción de clientes morosos en los conjuntos de entrenamiento y prueba.\n",
    "\n",
    "\n",
    "3. ``random_state=5:``\n",
    "Este parámetro controla la aleatoriedad en la división de los datos. Al asignarle un valor entero (en este caso, ``5``), garantizas que la división se realice de la misma manera cada vez que ejecutes el código.\n",
    "\n",
    "**¿Por qué es útil?** Facilita la reproducibilidad de los resultados. Si no fijas un ``random_state``, cada ejecución dividirá los datos de forma diferente, lo que puede llevar a variaciones en el rendimiento del modelo.\n",
    "\n",
    "**Analogía**: Imagina que tienes una baraja de cartas y quieres repartirla al azar. ``random_state`` sería como fijar una semilla para el generador de números aleatorios que se usa para mezclar las cartas. Si usas la misma semilla cada vez, obtendrás la misma secuencia de cartas.\n",
    "\n",
    "\n",
    "\n",
    "En resumen:\n",
    "\n",
    "``test_size`` define cuánto de tus datos usarás para probar tu modelo al final.\n",
    "\n",
    "``stratify`` asegura que las proporciones de las diferentes categorías en tus datos se mantengan al dividir los datos.\n",
    "\n",
    "``random_state`` te permite obtener los mismos resultados cada vez que corres el código, lo cual es útil para la reproducibilidad.\n",
    "\n",
    "Espero que esta explicación te sea de gran ayuda. ¡No dudes en preguntar si tienes más dudas!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f414e21",
   "metadata": {},
   "source": [
    "## método holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6269fb26",
   "metadata": {},
   "source": [
    "En el momento de validar modelos de clasificación, necesitamos verificar si el modelo está realmente generalizando, es decir, si está comprendiendo el patrón de los datos y clasificando correctamente datos nuevos. La estrategia más simple para evaluar esta generalización, conocida como **holdout**, consiste en dividir los datos en dos partes: un conjunto de datos de **entrenamiento** y otro de **prueba**. El conjunto de entrenamiento se utiliza para entrenar el modelo, mientras que el conjunto de prueba se usa para evaluar el rendimiento del modelo en datos no vistos anteriormente.\n",
    "\n",
    "Con la ayuda de la imagen a continuación, analiza la ejemplificación del método holdout en funcionamiento:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4625489",
   "metadata": {},
   "source": [
    "![01](img/01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2e114a",
   "metadata": {},
   "source": [
    "En algunos casos, especialmente cuando se realizan ajustes finos en los parámetros del modelo, es útil tener un conjunto de validación adicional. En este caso, la división se hace en tres partes: conjunto de entrenamiento, conjunto de validación y conjunto de prueba. El conjunto de validación se utiliza en la comparación de diferentes modelos, en la selección del modelo más adecuado y en el ajuste de los hiperparámetros. Mientras tanto, el conjunto de prueba sigue utilizándose para evaluar el rendimiento final del modelo elegido, después de todo el proceso de ajuste.\n",
    "\n",
    "Por eso, cuanto más se utilizan los mismos datos para tomar decisiones sobre configuraciones de mejoras en el modelo o elección de hiperparámetros, más comprometida se vuelve la confiabilidad de esos resultados al ser generalizados para datos nuevos y no vistos. Esto ocurre porque las mejoras se hacen a partir de esos datos de validación.\n",
    "\n",
    "Es posible percibir que las mejoras aplicadas desempeñan un papel fundamental para resolver el problema. Sin embargo, para asegurar que el rendimiento del modelo permanezca consistente en relación a los datos del mundo real, que no fueron vistos en el entrenamiento o en la mejora de los modelos, la estrategia de la división entre 3 conjuntos de datos, como se puede analizar en la imagen siguiente, ofrece una buena dirección final, ya que indica si el modelo elegido está sesgado o no en relación a los datos de validación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f66e4",
   "metadata": {},
   "source": [
    "![02](img/02.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
